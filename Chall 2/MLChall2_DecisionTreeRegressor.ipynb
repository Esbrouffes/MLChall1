{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-b8bcda159987>, line 120)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-b8bcda159987>\"\u001b[1;36m, line \u001b[1;32m120\u001b[0m\n\u001b[1;33m    Avec plusieurs run du modèle DT, on s'aperçoit que le score varie entre 0.70 et 0.94.\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# librairies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from random import shuffle\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, f1_score, precision_score, recall_score, mean_squared_error\n",
    "\n",
    "# import des données\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "yt = pd.read_csv('challenge_youtube_toxic.csv', encoding = 'latin1', engine = 'python', sep=';')\n",
    "\n",
    "# Préparation des données (input et output)\n",
    "# On utilise LabelEncoder pour remplacer les colonnes contenant du texte, par des numéros.\n",
    "# Pour chaque colonne, on attribue un numéro unique aux valeurs. S'il y a deux valeurs identiques dans la colonne\n",
    "# contenant des chaînes de caractères, le numéro sera le même. Par exemple, 'LeHuffPost' aura un numéro unique dans\n",
    "# la colonne channel_name_n.\n",
    "\n",
    "X = yt\n",
    "y = yt['nbrMotInsulte'] # variable de sortie\n",
    "X.drop(['nbrMotInsulte'], axis = 1)\n",
    "\n",
    "le_channel_name = LabelEncoder()\n",
    "le_video_id_court = LabelEncoder()\n",
    "le_video_id = LabelEncoder()\n",
    "# le_channel_id = LabelEncoder() # on n'utilise pas channel_id_n car channel_name_n contient déjà toutes les informations.\n",
    "le_categorie_new = LabelEncoder()\n",
    "le_categ_inst = LabelEncoder()\n",
    "\n",
    "# Dans ce qui suit, on rajoute les colonnes numériques, et supprimons les colonnes chaînes de caractère.\n",
    "# nous n'avons pas besoin des colonnes video_id_n et video_id_court_n car toutes les valeurs sont différentes\n",
    "# et n'aideront pas à la séparation au niveau d'un noeud dans l'arbre de décision.\n",
    "\n",
    "X['channel_name_n'] = le_channel_name.fit_transform(X['channel_name'])\n",
    "# X['video_id_court_n'] = le_video_id_court.fit_transform(X['video_id_court'])\n",
    "# X['video_id_n'] = le_video_id.fit_transform(X['video_id'])\n",
    "# X['channel_id_n'] = le_channel_id.fit_transform(X['channel_id'])\n",
    "X['categorie_new_n'] = le_categorie_new.fit_transform(X['categorie_new'])\n",
    "X['categ_inst_n'] = le_categ_inst.fit_transform(X['categ_inst'])\n",
    "\n",
    "X = X.drop(['video_id_court', 'video_id', 'channel_id', 'channel_name',\\\n",
    "                  'categorie_new', 'categ_inst'], axis = 'columns')\n",
    "\n",
    "# Les données d'entrainement et de test.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state = 1)\n",
    "\n",
    "# On construit le modèle d'arbre de décision + fit sur le training set.\n",
    "\n",
    "model = tree.DecisionTreeRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test) # y_prediction\n",
    "\n",
    "# Validating the model ?\n",
    "# print(y_pred, y_test)\n",
    "\n",
    "print(f'Mean absolute error is{mean_absolute_error(y_test, y_pred) : .2f}')\n",
    "\n",
    "# Other metrics for validation ?\n",
    "# print(f'Accuracy score is{accuracy_score(y_test, y_pred) : .2f}')\n",
    "# print(f'F1-score is{f1_score(y_test, y_pred, average=\"macro\") : .2f}')\n",
    "# print(f'Precision is{precision_score(y_test, y_pred, average=\"macro\"): .2f}')\n",
    "# print(f'Recall is{recall_score(y_test, y_pred, average=\"macro\"): .2f}')\n",
    "\n",
    "# on essaye différents paramètres afin d'optimiser l'arbre de décision\n",
    "\n",
    "# criteria = ['mse', 'friedman_mse', 'mae']\n",
    "# splitting_criteria = ['best', 'random']\n",
    "tree_depth = [i for i in range(4, 25)] # le mse est trop grand si la profondeur de \n",
    "                                        # l'arbre est trop faible et il faut faire attention à ne pas overffiter\n",
    "sample_split = [i for i in range(2,10)]\n",
    "sample_leaf = [i for i in range(1,6)]\n",
    "\n",
    "# on garde les mêmes train set et test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state = 1)\n",
    "best_depth = 0\n",
    "best_min_samples_split = 0\n",
    "best_min_samples_leaf = 0\n",
    "best_mse = 10**4\n",
    "for depth in tree_depth :\n",
    "    for split_sample in sample_split :\n",
    "        for leaf_sample in sample_leaf :\n",
    "            model = tree.DecisionTreeRegressor(criterion='mse', splitter='best', max_depth=depth, min_samples_split=split_sample, min_samples_leaf=leaf_sample)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            if mean_squared_error(y_test, y_pred) < best_mse :\n",
    "                best_mse = mean_squared_error(y_test, y_pred)\n",
    "                best_depth = depth\n",
    "                best_min_samples_split = split_sample\n",
    "                best_min_samples_leaf = leaf_sample\n",
    "            else :\n",
    "                best_mse = best_mse\n",
    "            print('( Tree depth :', depth, ', min_samples_split :', split_sample,\\\n",
    "                  ', min_samples_leaf :', leaf_sample, ')', 'Mean squared error :',\\\n",
    "                  mean_squared_error(y_test, y_pred))\n",
    "print('( Best depth :', best_depth, ', best_min_samples_split :', best_min_samples_split,\\\n",
    "      ', best_min_samples_leaf :', best_min_samples_leaf, ')', 'Best mean squared error :',\\\n",
    "      best_mse)\n",
    "\n",
    "# K-fold pou le cross-validation, avec les meilleurs paramètres qu'on a trouvé ci-dessus\n",
    "\n",
    "scores = []\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 6)\n",
    "for train_index, test_index in kf.split(X) :\n",
    "    # print(train_index, test_index)\n",
    "    # print(type(train_index))\n",
    "    X_train, X_test, y_train, y_test = X.to_numpy()[train_index, :], X.to_numpy()[test_index, :], y.to_numpy()[train_index], y.to_numpy()[test_index]\n",
    "    model = tree.DecisionTreeRegressor(max_depth=10, min_samples_split=2, min_samples_leaf=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    scores.append(model.score(X_test, y_test))\n",
    "print('Score du modèle :', np.mean(scores))\n",
    "\n",
    "Avec plusieurs run du modèle DT, on s'aperçoit que le score varie entre 0.70 et 0.94.\n",
    "\n",
    "RANDOM FOREST REGRESSOR\n",
    "\n",
    "# RandomForestRegressor with cross-validation\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "random_forest_score = []\n",
    "kf = KFold(n_splits = 6)\n",
    "for train_index, test_index in kf.split(X) :\n",
    "    X_train, X_test, y_train, y_test = X.to_numpy()[train_index, :], X.to_numpy()[test_index, :], y.to_numpy()[train_index], y.to_numpy()[test_index]\n",
    "    rd = RandomForestRegressor(n_estimators=40, max_depth=10, min_samples_split=2, min_samples_leaf=1)\n",
    "    rd.fit(X_train, y_train)\n",
    "    random_forest_score.append(rd.score(X_test, y_test))\n",
    "print(np.mean(random_forest_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
